{
	"$schema": "../../../src/schemas/section.json",
	"name": "tech",
	"content": [
		[
			"heading",
			{
				"text": "核心技术",
				"level": 1
			}
		],
		[
			"paragraph",
			[
				"以人工智能技术为核心，综合利用ASR、TTS、计算机视觉等各种AI能力打造出的川观新闻数字记者，核心技术包括两个方面：数字人形象打造和虚拟内容制作。"
			]
		],
		[
			"paragraph",
			[
				"1、数字人形象打造：形象打造的第一步是确定数字人的大致人设及应用场景。首个川观数字记者小观的设定是一个身高165cm、瓜子脸、大眼睛的短发女孩；第二步进行形象设计，绘制原画和三视图，以及招牌动作表情。第三步就是根据原画形象进行资产制作，包括模型搭建、UV设计、贴图绘制、骨骼绑定、服装等等。小观采用Maya X-gen来定制发型，拥有约10万根发丝；面部皮肤采用3DScan高精度8192*8192扫描模型贴图；在此基础上绘制妆容，从而还原真人的细节及材质特征；在UE中模拟了皮肤的透光与次表面反射效果，以增强角色的真实感；同时我们采用FACS参照与标准,让面部绑定了51个表情，可以非线性地组合出任意表情；服装的贴图使用XYZ高精度贴图进行映射来得到真实的布料纹理，采用布料的实时模拟结算，在UE中使用uDraper完成，对服装的物理效果和真实感达到超高保真度。"
			]
		],
		[
			"paragraph",
			[
				"2、虚拟内容制作：最核心的应用场景便是内容生产，我们提供两种内容生产方案：第一种是基于唇动合成、眼动合成以及头部的摇动合成的2D方案。现阶段的主要方式是建立文本、音频、视频之间的映射关系，从而实现自动对口型的效果。对于表情和动作，当前主要的触发机制是通过随机算法或者脚本的形式人工预设。不仅如此，还支持英文以及中国各地方言。第二种是基于模型驱动的3D合成方案。3D人脸建模驱动的人脸面部生成方案的核心技术则是动作捕捉，生成3D数字人运动，最大可实现毫米级误差。模型驱动都是通过真人使用光捕或者惯捕进行动作捕捉，支持预制内容录播和实时内容直播。动画技术核心包括动作数据的多角色retargeting、角色与场景的IK反馈、碰撞以及运动过程中动作的实时碰撞检测和反算修正。"
			]
		]
	]
}
